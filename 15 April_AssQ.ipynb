{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52f05e09-502d-4ef5-bd71-1497df7a1d20",
   "metadata": {},
   "source": [
    "### Q1. You are working on a machine learning project where you have a dataset containing numerical and categorical features. You have identified that some of the features are highly correlated and there are missing values in some of the columns. You want to build a pipeline that automates the feature engineering process and handles the missing values.\n",
    "### Design a pipeline that includes the following steps\"\n",
    "- Use an automated feature selection method to identify the important features in the dataset Create a numerical pipeline that includes the following steps\"\n",
    "    - Impute the missing values in the numerical columns using the mean of the column values\n",
    "    - Scale the numerical columns using standardization\n",
    "- Create a categorical pipeline that includes the following steps\"\n",
    "    - Impute the missing values in the categorical columns using the most frequent value of the column\n",
    "    - One-hot encode the categorical columns\n",
    "- Combine the numerical and categorical pipelines using a ColumnTransformer\n",
    "- Use a Random Forest Classifier to build the final model\n",
    "- Evaluate the accuracy of the model on the test dataset\n",
    "\n",
    "### Note! Your solution should include code snippets for each step of the pipeline, and a brief explanation of each step. You should also provide an interpretation of the results and suggest possible improvements for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c5239049-0431-4db9-9122-9bd7fc87a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from seaborn import load_dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ce1c44b8-cb4b-4789-a861-e7293ec3a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ed0d0191-0a49-4166-bd42-7951419e5ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_iris()\n",
    "# data = dataset.data\n",
    "# df = pd.DataFrame(data,columns=dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "86913567-5859-476f-b724-99b49d9433ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"target\"] = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ff9d9f56-4013-4151-b68b-b0129d6b5d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6e97759d-17a6-4579-b2f1-30a21d9ca8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "14ca8976-ec3f-4631-8fcc-ecd8b5cb891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df[\"species\"] = encoder.fit_transform(df[\"species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9cdc39ef-711d-4a1e-bf6b-045be5f93617",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"]\n",
    "# cat_cols = [\"species\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "25d91619-4286-4bee-a502-379563d1ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating numerical pipeline : \n",
    "\n",
    "num_pipeline = Pipeline(\n",
    "    steps = [\n",
    "        (\"imputer\",SimpleImputer(strategy=\"mean\")), # applying simple imputer to impute any missing values with mean value.\n",
    "        (\"scaler\",StandardScaler()), # applying standard scaler to scale our data point in one scale.\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "46dda381-be56-47ff-a814-f226840f9915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating categorical pipeline : \n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    steps = [\n",
    "        (\"imputer\",SimpleImputer(strategy=\"most_frequent\")), # applying simple imputer to impute any missing values with mean value.\n",
    "        (\"OneHotEncoder\",OneHotEncoder()), # applying one hot encoding to our categoical column to convert into numerical column.\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9a908f85-602a-4b6e-ae38-feb04f743b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    (\"num_pipeline\",num_pipeline,num_cols),\n",
    "    # (\"cat_pipeline\",cat_pipeline,cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4cea5d85-c6b8-4b23-9c32-2d224fb33ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = df.iloc[:,:-1],df[\"species\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "10594b9a-2699-4665-bf12-719000b40f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a911768e-ed6c-4ffb-9593-86a775baf18c",
   "metadata": {},
   "source": [
    "### Q2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "920ade92-091a-4bff-a34d-c961c3c534cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3e2c1a5b-0192-4b52-bebd-e89cf329fda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\":RandomForestClassifier(),\n",
    "    \"Logistic Regression\":LogisticRegression()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e24a9459-c8c4-490e-864e-577cd76cd94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train,y_train,X_test,y_test,models):\n",
    "    report = {}\n",
    "    for i in range(len(models)):\n",
    "        model = list(models.values())[i]\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        test_model_score = accuracy_score(y_test,y_pred)\n",
    "        report[list(models.keys())[i]] = test_model_score\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4f0e7020-0ade-44a6-84c7-86e519c41f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest': 1.0, 'Logistic Regression': 1.0}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(X_train,y_train,X_test,y_test,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a9a9ce-23f5-4498-b9ef-af5434248da8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
