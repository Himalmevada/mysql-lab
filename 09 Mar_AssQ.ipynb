{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que - 1 :  What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **PMF :**\n",
    "#### The Probability Mass Function (PMF) is a mathematical function used in probability theory to describe the probability distribution of a discrete random variable.\n",
    "\n",
    "#### The PMF is defined as a function that maps each possible value of the discrete random variable to the probability of that value occurring. In other words, it gives the probability that a random variable X takes on a specific value x, written as P(X = x).\n",
    "\n",
    "#### The PMF satisfies two important properties:\n",
    "\n",
    "#### The PMF is non-negative for all values of x: P(X = x) ≥ 0\n",
    "#### The sum of the PMF over all possible values of x is equal to 1: ∑ P(X = x) = 1\n",
    "#### The PMF is often represented graphically as a bar chart or histogram, where the height of each bar represents the probability of the  corresponding value.\n",
    "\n",
    "#### The PMF is a useful tool in probability theory because it allows us to compute probabilities for specific outcomes and to compare the  likelihood of different outcomes. It also forms the basis for other probability functions such as the cumulative distribution function (CDF) and the expected value.\n",
    "\n",
    "#### **Example :**\n",
    "#### Let's consider a discrete random variable Y that represents the outcome of rolling a fair six-sided die. The PMF of this random variable can be expressed as:\n",
    "\n",
    "#### P(Y = i) = 1/6 for i = 1,2,3,4,5,6\n",
    "\n",
    "#### The PMF P(Y=i) gives the probability that the outcome of rolling the die is i. For example, the probability of rolling a 3 can be calculated as:\n",
    "\n",
    "#### P(Y = 3) = 1/6 ≈ 0.167\n",
    "\n",
    "#### Note that in this case, the PMF takes only discrete values since the possible outcomes of rolling a die are discrete (1, 2, 3, 4, 5, or 6).\n",
    "\n",
    "#### **PDF :**\n",
    "#### The Probability Density Function (PDF) is a mathematical function used in probability theory to describe the probability distribution of a continuous random variable.\n",
    "\n",
    "#### Unlike the Probability Mass Function (PMF), which is used for discrete random variables, the PDF is used for continuous random variables. The PDF is defined as a function that describes the relative likelihood of a continuous random variable taking on a particular value within a certain range. In other words, it gives the probability density at a particular point, rather than the probability of a specific value.\n",
    "\n",
    "#### The PDF satisfies two important properties:\n",
    "\n",
    "#### The PDF is non-negative for all values of x: f(x) ≥ 0\n",
    "#### The total area under the PDF curve is equal to 1: ∫ f(x) dx = 1, where the integral is taken over the entire range of the random variable.\n",
    "#### The PDF is often represented graphically as a smooth curve, where the area under the curve between two points corresponds to the probability that the random variable takes on a value within that range.\n",
    "\n",
    "#### The PDF is a useful tool in probability theory because it allows us to compute probabilities for ranges of values and to compare the likelihood of different ranges. It also forms the basis for other probability functions such as the cumulative distribution function (CDF) and the expected value.\n",
    "\n",
    "#### Let's consider a continuous random variable X that represents the height of people in a certain population, with a normal distribution with mean 170 cm and standard deviation 10 cm. The PDF of this random variable can be expressed as:\n",
    "\n",
    "#### f(x) = (1 / (σ * sqrt(2π))) * exp(-(x-μ)^2 / (2σ^2))\n",
    "\n",
    "#### where μ = 170, σ = 10, and exp denotes the exponential function. The PDF f(x) gives the probability density of observing a person with height x. For example, the probability density of observing a person with height of 180 cm can be calculated as:\n",
    "\n",
    "#### f(180) = (1 / (10 * sqrt(2π))) * exp(-(180-170)^2 / (2*10^2)) ≈ 0.039\n",
    "\n",
    "#### **Example :**\n",
    "#### Let's consider an example of a Probability Density Function (PDF) for the weight of apples produced in an orchard. Suppose the PDF of the weight of apples produced in the orchard is a normal distribution with a mean weight of 150 grams and a standard deviation of 20 grams.\n",
    "\n",
    "#### We can use this information to calculate the probability of picking an apple with a weight less than or equal to 140 grams. We would first calculate the z-score for 140 grams, which is (140 - 150) / 20 = -0.5. Then, we would look up the area to the left of the z-score in the normal distribution table or use a calculator to find that the probability of picking an apple with a weight less than or equal to 140 grams is 0.3085.\n",
    "\n",
    "#### Similarly, we can use the PDF to calculate the probability of picking an apple with a weight between 140 grams and 160 grams. We would calculate the z-scores for both weights (140 grams: z = -0.5, 160 grams: z = 0.5) and find the area between the two z-scores using the normal distribution table or calculator. The probability of picking an apple with a weight between 140 grams and 160 grams is 0.3829."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que - 2 :  What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Cumulative Density Function (CDF) is a mathematical function that shows the probability of a random variable being less than or equal to a certain value. It is often used to describe the distribution of a dataset and is calculated by accumulating the probability density function (PDF) over a range of values.\n",
    "\n",
    "#### **Example :** let's say we have a dataset of test scores for a class of 20 students. The scores range from 50 to 100, with a mean score of 80. To create a CDF for this dataset, we would first calculate the PDF by plotting the frequency of scores at each value. Then, we would add up the PDF values at each score and plot the cumulative sum. This would give us a graph showing the probability of a score being less than or equal to a certain value.\n",
    "\n",
    "#### CDFs are used for a variety of purposes, including statistical analysis, hypothesis testing, and modeling. They provide a way to visualize the distribution of a dataset and can be used to calculate percentiles, confidence intervals, and other statistical measures. They are particularly useful in fields such as finance, engineering, and science, where probability distributions play a central role."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que - 3 : What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The normal distribution is a very common and important probability distribution that can be used to model many real-world phenomena. Some examples of situations where the normal distribution might be used as a model include:\n",
    "\n",
    "#### -> Heights and weights of people\n",
    "#### -> Test scores\n",
    "#### -> Blood pressure measurements\n",
    "#### -> IQ scores\n",
    "#### -> Errors in measurements or experimental data\n",
    "#### -> Natural phenomena, such as the distribution of rainfall or temperatures\n",
    "\n",
    "#### The normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). The mean is the center of the distribution and indicates the most likely value of the variable being measured. The standard deviation measures the spread or dispersion of the distribution, indicating how much the data deviates from the mean.\n",
    "\n",
    "#### The shape of the normal distribution is determined by the mean and standard deviation. The mean is the location of the peak of the curve, and the standard deviation determines the width of the curve. A larger standard deviation results in a wider and flatter curve, indicating more variability in the data. A smaller standard deviation results in a narrower and taller curve, indicating less variability in the data.\n",
    "\n",
    "#### The normal distribution is symmetric, with the left and right tails of the curve being mirror images of each other. The total area under the curve is equal to 1, meaning that the probability of any particular value occurring is always between 0 and 1.\n",
    "\n",
    "#### Overall, the normal distribution is a useful tool for modeling real-world phenomena and understanding the characteristics of random variables. It is widely used in statistics, science, engineering, and many other fields."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que - 4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The normal distribution is one of the most important and widely used probability distributions in statistics and data analysis. It is a continuous probability distribution that is symmetric, bell-shaped, and characterized by its mean and standard deviation. The importance of normal distribution lies in its ability to model and describe many real-world phenomena, as well as its use in statistical inference and hypothesis testing.\n",
    "\n",
    "#### Here are a few examples of real-life situations where the normal distribution is commonly used as a model:\n",
    "\n",
    "#### Heights and weights of people: The distribution of heights and weights of a population often follows a normal distribution, with the mean being the average height or weight and the standard deviation indicating the degree of variability in the data.\n",
    "\n",
    "#### Test scores: Many standardized tests, such as the SAT or GRE, are designed to follow a normal distribution, with the mean score representing the average performance of test-takers and the standard deviation indicating the spread of scores.\n",
    "\n",
    "#### IQ scores: IQ scores are often assumed to follow a normal distribution, with the mean being set at 100 and the standard deviation being 15. This allows for comparisons of IQ scores across different populations.\n",
    "\n",
    "#### Stock prices: Stock prices are often modeled using a log-normal distribution, which is a variation of the normal distribution. This allows for predictions of the likelihood of stock prices reaching certain levels over time.\n",
    "\n",
    "#### Errors in measurements: Errors in measurements or experimental data are often assumed to be normally distributed, with the mean representing the true value and the standard deviation indicating the degree of measurement error.\n",
    "\n",
    "#### The normal distribution is important because it provides a useful framework for analyzing and understanding random variables and their probabilities. It is also widely used in hypothesis testing, where it is often assumed that data follow a normal distribution in order to perform tests of significance and make inferences about population parameters. In addition, the central limit theorem states that the sum of a large number of independent and identically distributed random variables will approach a normal distribution, making it a fundamental concept in many areas of statistics and data analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que - 5 : What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Bernoulli distribution is a discrete probability distribution that models the outcomes of a single experiment or trial that can result in either success or failure. It is named after the Swiss mathematician Jacob Bernoulli, who developed the concept in the 17th century.\n",
    "\n",
    "#### The Bernoulli distribution has a single parameter, p, which represents the probability of success. The probability mass function (PMF) of the Bernoulli distribution is:\n",
    "\n",
    "#### P(X = 1) = p\n",
    "#### P(X = 0) = 1 - p\n",
    "\n",
    "#### where X is the random variable that represents the outcome of the experiment, and takes on the value 1 if the experiment is a success, and 0 if the experiment is a failure.\n",
    "\n",
    "#### An example of the Bernoulli distribution could be flipping a coin. If we define \"heads\" as a success and \"tails\" as a failure, then the Bernoulli distribution can be used to model the probability of flipping a heads.\n",
    "\n",
    "#### The binomial distribution, on the other hand, is a discrete probability distribution that models the number of successes in a fixed number of independent and identical trials. It is based on the Bernoulli distribution, as each trial can be modeled using a Bernoulli distribution.\n",
    "\n",
    "#### The binomial distribution has two parameters: n, the number of trials, and p, the probability of success on each trial. The probability mass function (PMF) of the binomial distribution is:\n",
    "\n",
    "#### P(X = k) = (n choose k) * p^k * (1-p)^(n-k)\n",
    "\n",
    "#### where X is the random variable that represents the number of successes, k is a non-negative integer less than or equal to n, and (n choose k) is the binomial coefficient, which represents the number of ways to choose k successes from n trials.\n",
    "\n",
    "#### The main difference between the Bernoulli distribution and the binomial distribution is that the Bernoulli distribution models the outcomes of a single trial, while the binomial distribution models the number of successes in a fixed number of trials. In other words, the Bernoulli distribution is a special case of the binomial distribution, where n=1.\n",
    "\n",
    "#### To summarize, the Bernoulli distribution is a probability distribution that models the outcomes of a single experiment with two possible outcomes, while the binomial distribution models the number of successes in a fixed number of independent and identical trials, each of which can be modeled using a Bernoulli distribution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que - 6 : Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to find z-score first using this formula :\n",
    "#### z = (x - μ) / σ\n",
    "#### z = (60 - 50) / 10\n",
    "#### z = 1\n",
    "\n",
    "#### This tells us that 60 is 1 standard deviation above the mean. We then look up the area to the right of z = 1 in the standard normal distribution table, which is 0.1587 before this right area we got left area which is 0.84134 and now we subtract 1 from this left area so we finally got right area (1 - 0.84134 = 0.1587 ). \n",
    "#### This means that the probability of selecting an observation greater than 60 is 0.1587, or approximately 15.87%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que - 7 : Explain uniform Distribution with an example."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniform distribution is a probability distribution where all possible outcomes of an experiment are equally likely to occur. It is also known as the rectangular distribution, as the probability density function (PDF) is constant over a given interval.\n",
    "\n",
    "#### An example of the uniform distribution is rolling a fair six-sided die. Each of the six possible outcomes (1, 2, 3, 4, 5, 6) has an equal chance of occurring, and the probability of rolling any particular value is 1/6. The PDF of the uniform distribution in this case would be:\n",
    "\n",
    "#### f(x) = 1/6 for x = 1, 2, 3, 4, 5, 6\n",
    "\n",
    "#### This means that the probability of rolling any particular value is constant and equal to 1/6. Another example of the uniform distribution is selecting a random number between two given values, such as selecting a number between 1 and 10. Each possible value between 1 and 10 has an equal chance of being selected, and the probability density function is:\n",
    "\n",
    "#### f(x) = 1/10 for x = 1, 2, 3, ..., 10\n",
    "\n",
    "#### In general, the uniform distribution can be used to model situations where all outcomes are equally likely to occur, such as the distribution of arrival times at a bus stop, or the distribution of the height of individuals in a population where there is no bias towards any particular height."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que - 8 : What is the z score? State the importance of the z score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The z score, also known as the standard score, is a measure of how many standard deviations an observation or data point is from the mean of the distribution. It is calculated by subtracting the mean from the data point and then dividing the result by the standard deviation of the distribution.\n",
    "\n",
    "#### The formula for calculating the z score is:\n",
    "\n",
    "#### z = (x - μ) / σ\n",
    "\n",
    "#### where x is the data point, μ is the mean of the distribution, and σ is the standard deviation of the distribution.\n",
    "\n",
    "#### The z score is important because it standardizes the distribution and allows us to compare observations from different distributions on a common scale. By converting data points into z scores, we can determine how unusual or extreme an observation is compared to the rest of the distribution.\n",
    "\n",
    "#### The z score is also used to calculate probabilities associated with the normal distribution. In a standard normal distribution, the mean is 0 and the standard deviation is 1, so the z score for any data point in this distribution can be directly interpreted as the probability of obtaining a value less than or equal to that data point.\n",
    "\n",
    "#### In summary, the z score is a standardized measure of how far a data point is from the mean of a distribution in terms of standard deviations, and it is useful for comparing observations across different distributions and calculating probabilities associated with the normal distribution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que - 9 : What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Central Limit Theorem (CLT) is a statistical concept that states that for any given population, if we take sufficiently large random samples from that population, the distribution of the means of those samples will be approximately normally distributed, regardless of the underlying distribution of the population.\n",
    "\n",
    "#### In other words, the Central Limit Theorem states that as the sample size increases, the sampling distribution of the sample means becomes more and more normally distributed, with a mean equal to the population mean and a standard deviation equal to the population standard deviation divided by the square root of the sample size. This means that even if the population is not normally distributed, the means of sufficiently large samples from that population will tend to follow a normal distribution.\n",
    "\n",
    "#### The significance of the Central Limit Theorem is that it allows us to make inferences about a population based on a sample of data, even if we do not know the underlying distribution of the population. By assuming that the sample means follow a normal distribution, we can use statistical methods such as hypothesis testing and confidence intervals to make accurate predictions about the population parameters.\n",
    "\n",
    "#### In addition, the Central Limit Theorem is important in many areas of research and data analysis, as it allows us to make statistical inferences and draw conclusions about populations based on relatively small samples of data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que - 10 : State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Central Limit Theorem (CLT) has certain assumptions that must be met for it to hold true. These assumptions include:\n",
    "\n",
    "#### Independence: The samples must be selected independently and randomly from the population.\n",
    "#### Sample size: The sample size must be sufficiently large. As a general rule of thumb, a sample size of at least 30 is considered sufficient for the CLT to hold true, but this can vary depending on the underlying distribution of the population.\n",
    "#### Finite variance: The population from which the samples are drawn must have a finite variance. If the variance is infinite or unknown, the CLT may not hold true.\n",
    "#### Identically distributed: The samples must be drawn from the same population with the same distribution.\n",
    "#### It is important to note that violating any of these assumptions can lead to biased or incorrect results. Therefore, it is essential to carefully consider these assumptions and to ensure that they are met when using the Central Limit Theorem in statistical analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "72b2382ece9768098284d92bbc69d35954e75b60d1e25897d1389c232f4796f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
